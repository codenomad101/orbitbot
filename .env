# Llama.cpp Configuration
LLAMA_MODEL_PATH=./models/tinyllama-1.1b-chat.gguf
LLAMA_CONTEXT_LENGTH=2048
LLAMA_N_GPU_LAYERS=0
LLAMA_N_THREADS=4
LLAMA_N_BATCH=512
LLAMA_TEMP=0.7
LLAMA_TOP_P=0.9
LLAMA_REPEAT_PENALTY=1.1
#ollama-config
OLLAMA_HOST=http://localhost:11435
OLLAMA_MODEL=llama3.2:1b
#OLLAMA_MODEL=tinyllama:latest

# Application Configuration
APP_HOST=127.0.0.1
APP_PORT=8000
DEBUG=True

# Vector Store Configuration
VECTOR_STORE_PATH=./data/vector_store
CHUNK_SIZE=256
CHUNK_OVERLAP=200

# Embedding Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# Upload Configuration
UPLOAD_DIR=./backend/uploads
MAX_FILE_SIZE=10485760

# Retrieval Configuration
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.3

